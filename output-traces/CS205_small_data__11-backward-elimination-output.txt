--- Machine Information ---
CPU:
  Model Name: AMD EPYC 7B12
  Architecture: x86_64
  CPU(s) (Logical): 2
  On-line CPU(s) list: 0,1
  Core(s) per socket: 1
  Socket(s): 1
  Thread(s) per core: 2
  L3 Cache: 16 MiB (1 instance)
Memory:
  Total: 12.7 GB
OS:
  System: Linux
  Release: 6.1.123+
  Version: #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025
---------------------------

Welcome to Akshat Shah's Feature Selection Algorithm.

Type in the name of the file to test : CS205_small_Data__11.txt

Successfully loaded 500 instances from 'CS205_small_Data__11.txt'.

This dataset has 12 features (not including the class attribute), with 500 instances.

Running nearest neighbor with all 12 features, using "leaving-one-out" evaluation, I get an accuracy of 72.60%


Type the number of the algorithm you want to run.
1) Forward Selection
2) Backward Elimination
Enter choice (1 or 2): 2
Running nearest neighbor with all 12 features, using "leaving-one-out" evaluation, I get an accuracy of 72.60%

Beginning search.

On level 1 of the search tree, considering removing feature from {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}.
        Using feature(s) {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12} accuracy is 69.60%
        Using feature(s) {1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12} accuracy is 69.60%
        Using feature(s) {1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12} accuracy is 77.20%
        Using feature(s) {1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12} accuracy is 77.20%
        Using feature(s) {1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 77.40%
        Using feature(s) {1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12} accuracy is 75.00%
        Using feature(s) {1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12} accuracy is 74.00%
        Using feature(s) {1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12} accuracy is 74.80%
        Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12} accuracy is 74.40%
        Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12} accuracy is 74.20%
        Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12} accuracy is 74.60%
        Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11} accuracy is 76.00%
Feature set {1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12} was best, accuracy 77.40%

On level 2 of the search tree, considering removing feature from {1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12}.
        Using feature(s) {2, 3, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 71.40%
        Using feature(s) {1, 3, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 75.20%
        Using feature(s) {1, 2, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 78.20%
        Using feature(s) {1, 2, 3, 6, 7, 8, 9, 10, 11, 12} accuracy is 77.80%
        Using feature(s) {1, 2, 3, 4, 7, 8, 9, 10, 11, 12} accuracy is 77.00%
        Using feature(s) {1, 2, 3, 4, 6, 8, 9, 10, 11, 12} accuracy is 77.60%
        Using feature(s) {1, 2, 3, 4, 6, 7, 9, 10, 11, 12} accuracy is 74.20%
        Using feature(s) {1, 2, 3, 4, 6, 7, 8, 10, 11, 12} accuracy is 77.40%
        Using feature(s) {1, 2, 3, 4, 6, 7, 8, 9, 11, 12} accuracy is 76.60%
        Using feature(s) {1, 2, 3, 4, 6, 7, 8, 9, 10, 12} accuracy is 77.20%
        Using feature(s) {1, 2, 3, 4, 6, 7, 8, 9, 10, 11} accuracy is 78.00%
Feature set {1, 2, 4, 6, 7, 8, 9, 10, 11, 12} was best, accuracy 78.20%

On level 3 of the search tree, considering removing feature from {1, 2, 4, 6, 7, 8, 9, 10, 11, 12}.
        Using feature(s) {2, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 74.60%
        Using feature(s) {1, 4, 6, 7, 8, 9, 10, 11, 12} accuracy is 78.80%
        Using feature(s) {1, 2, 6, 7, 8, 9, 10, 11, 12} accuracy is 81.00%
        Using feature(s) {1, 2, 4, 7, 8, 9, 10, 11, 12} accuracy is 78.40%
        Using feature(s) {1, 2, 4, 6, 8, 9, 10, 11, 12} accuracy is 79.20%
        Using feature(s) {1, 2, 4, 6, 7, 9, 10, 11, 12} accuracy is 77.40%
        Using feature(s) {1, 2, 4, 6, 7, 8, 10, 11, 12} accuracy is 77.60%
        Using feature(s) {1, 2, 4, 6, 7, 8, 9, 11, 12} accuracy is 79.80%
        Using feature(s) {1, 2, 4, 6, 7, 8, 9, 10, 12} accuracy is 78.60%
        Using feature(s) {1, 2, 4, 6, 7, 8, 9, 10, 11} accuracy is 79.00%
Feature set {1, 2, 6, 7, 8, 9, 10, 11, 12} was best, accuracy 81.00%

On level 4 of the search tree, considering removing feature from {1, 2, 6, 7, 8, 9, 10, 11, 12}.
        Using feature(s) {2, 6, 7, 8, 9, 10, 11, 12} accuracy is 74.00%
        Using feature(s) {1, 6, 7, 8, 9, 10, 11, 12} accuracy is 82.80%
        Using feature(s) {1, 2, 7, 8, 9, 10, 11, 12} accuracy is 80.40%
        Using feature(s) {1, 2, 6, 8, 9, 10, 11, 12} accuracy is 82.40%
        Using feature(s) {1, 2, 6, 7, 9, 10, 11, 12} accuracy is 80.00%
        Using feature(s) {1, 2, 6, 7, 8, 10, 11, 12} accuracy is 81.20%
        Using feature(s) {1, 2, 6, 7, 8, 9, 11, 12} accuracy is 80.40%
        Using feature(s) {1, 2, 6, 7, 8, 9, 10, 12} accuracy is 81.60%
        Using feature(s) {1, 2, 6, 7, 8, 9, 10, 11} accuracy is 81.40%
Feature set {1, 6, 7, 8, 9, 10, 11, 12} was best, accuracy 82.80%

On level 5 of the search tree, considering removing feature from {1, 6, 7, 8, 9, 10, 11, 12}.
        Using feature(s) {6, 7, 8, 9, 10, 11, 12} accuracy is 74.40%
        Using feature(s) {1, 7, 8, 9, 10, 11, 12} accuracy is 81.00%
        Using feature(s) {1, 6, 8, 9, 10, 11, 12} accuracy is 82.80%
        Using feature(s) {1, 6, 7, 9, 10, 11, 12} accuracy is 80.60%
        Using feature(s) {1, 6, 7, 8, 10, 11, 12} accuracy is 85.60%
        Using feature(s) {1, 6, 7, 8, 9, 11, 12} accuracy is 80.60%
        Using feature(s) {1, 6, 7, 8, 9, 10, 12} accuracy is 83.00%
        Using feature(s) {1, 6, 7, 8, 9, 10, 11} accuracy is 84.00%
Feature set {1, 6, 7, 8, 10, 11, 12} was best, accuracy 85.60%

On level 6 of the search tree, considering removing feature from {1, 6, 7, 8, 10, 11, 12}.
        Using feature(s) {6, 7, 8, 10, 11, 12} accuracy is 75.80%
        Using feature(s) {1, 7, 8, 10, 11, 12} accuracy is 82.60%
        Using feature(s) {1, 6, 8, 10, 11, 12} accuracy is 85.20%
        Using feature(s) {1, 6, 7, 10, 11, 12} accuracy is 83.20%
        Using feature(s) {1, 6, 7, 8, 11, 12} accuracy is 85.40%
        Using feature(s) {1, 6, 7, 8, 10, 12} accuracy is 83.80%
        Using feature(s) {1, 6, 7, 8, 10, 11} accuracy is 83.40%
Feature set {1, 6, 7, 8, 11, 12} was best, accuracy 85.40%

(Warning, Accuracy has decreased! Continuing search in case of local maxima)
(Current best feature subset: {1, 6, 7, 8, 10, 11, 12}, accuracy: 85.60%)

On level 7 of the search tree, considering removing feature from {1, 6, 7, 8, 11, 12}.
        Using feature(s) {6, 7, 8, 11, 12} accuracy is 75.40%
        Using feature(s) {1, 7, 8, 11, 12} accuracy is 82.60%
        Using feature(s) {1, 6, 8, 11, 12} accuracy is 87.60%
        Using feature(s) {1, 6, 7, 11, 12} accuracy is 84.40%
        Using feature(s) {1, 6, 7, 8, 12} accuracy is 85.60%
        Using feature(s) {1, 6, 7, 8, 11} accuracy is 85.40%
Feature set {1, 6, 8, 11, 12} was best, accuracy 87.60%

On level 8 of the search tree, considering removing feature from {1, 6, 8, 11, 12}.
        Using feature(s) {6, 8, 11, 12} accuracy is 76.60%
        Using feature(s) {1, 8, 11, 12} accuracy is 82.60%
        Using feature(s) {1, 6, 11, 12} accuracy is 89.20%
        Using feature(s) {1, 6, 8, 12} accuracy is 87.80%
        Using feature(s) {1, 6, 8, 11} accuracy is 89.00%
Feature set {1, 11, 12, 6} was best, accuracy 89.20%

On level 9 of the search tree, considering removing feature from {1, 11, 12, 6}.
        Using feature(s) {6, 11, 12} accuracy is 74.40%
        Using feature(s) {1, 11, 12} accuracy is 84.20%
        Using feature(s) {1, 6, 12} accuracy is 91.80%
        Using feature(s) {1, 6, 11} accuracy is 91.40%
Feature set {1, 12, 6} was best, accuracy 91.80%

On level 10 of the search tree, considering removing feature from {1, 12, 6}.
        Using feature(s) {6, 12} accuracy is 75.00%
        Using feature(s) {1, 12} accuracy is 85.80%
        Using feature(s) {1, 6} accuracy is 96.60%
Feature set {1, 6} was best, accuracy 96.60%

On level 11 of the search tree, considering removing feature from {1, 6}.
        Using feature(s) {6} accuracy is 74.60%
        Using feature(s) {1} accuracy is 84.60%
Feature set {1} was best, accuracy 84.60%

(Warning, Accuracy has decreased! Continuing search in case of local maxima)
(Current best feature subset: {1, 6}, accuracy: 96.60%)

Feature set {} (representing initial all-feature baseline) accuracy is 72.60%

Finished search!! The best feature subset is {1, 6}, which has an accuracy of 96.60%

Algorithm finished in 26.50 seconds.